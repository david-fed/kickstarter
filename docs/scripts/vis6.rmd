---
title: "Visualization 6"
output: html_document
---

### 2D Visualization of sampled Title Embeddings

Our final visualization is more for fun than for in-depth analysis. We used a text embedding language model to generate embeddings for 50,000 project names in our dataset. These embeddings capture the semantic meaning of the words in each project name. To make the data more visually accessible, we reduced the embedding vectors' dimensions from 768 to 2 using PaCMAP and plotted them by category with Plotly.

The goal of this visualization is to see if clear clusters emerge â€” indicating that projects within the same category tend to group together based on the semantic meaning of their names.

```{python, eval = FALSE}
import pandas as pd
from sentence_transformers import SentenceTransformer
import pacmap
import pyarrow.feather as feather

# Load the CSV file and extract required columns
file_path = 'kickstarter_projects.csv'
data = pd.read_csv(file_path)

# Sample 50'000 datapoints
data = data.sample(50000)

# Clean the "Name" column (remove " (Canceled)")
data['Name'] = data['Name'].str.replace(r" \(Canceled\)$", "", regex=True)

ids = data['ID'].dropna().tolist()
names = data.loc[data['ID'].notna(), 'Name'].dropna().tolist()

# Generate embeddings
model = SentenceTransformer('all-mpnet-base-v2', device="cuda")
embeddings = model.encode(names, show_progress_bar=True)

# Save embeddings alongside IDs in Feather format
output = pd.DataFrame({'ID': ids, 'Embedding': list(embeddings)})
output_file = 'id_embeddings.feather'
feather.write_feather(output, output_file)

pacmap_model = pacmap.PaCMAP(n_components=2, verbose=True)
pacmap_results = pacmap_model.fit_transform(embeddings, init="pca")

# Create a dataframe with IDs and pacmap results
output = pd.DataFrame({
  'ID': ids,
  'DIM_1': pacmap_results[:, 0],
  'DIM_2': pacmap_results[:, 1]
})

# Save the pacmap results to a feather file
output_file = '../assets/id_pacmap_results.feather'
feather.write_feather(output, output_file)

print(f"Pacmap results saved in Feather format to {output_file}")

```

```{r, message = FALSE, warning = FALSE, tidy = 'styler'}
library(arrow)
library(dplyr)
library(plotly)

# Read the Feather file
embeddings <- read_feather("../assets/id_pacmap_results.feather")

# Join with the full dataset
merged_data <- merge(kickstarter, embeddings, by = "ID")

# Combine least frequent categories into "Other"
category_counts <- merged_data %>%
  count(Category, sort = TRUE)  # Count category occurrences

# Identify the 5 least frequent categories
least_frequent_categories <- tail(category_counts$Category, 5)

merged_data <- merged_data %>%
  mutate(Category = ifelse(Category %in% least_frequent_categories, "Other", Category))

# Sort the legend by Category frequency
sorted_categories <- merged_data %>%
  count(Category, sort = TRUE) %>%
  pull(Category)

merged_data$Category <- factor(merged_data$Category, levels = sorted_categories)

plot <- plot_ly(
  data = merged_data,
  x = ~UMAP_1,
  y = ~UMAP_2,
  split = ~Category,
  text = ~paste(
    "Title:", Name,
    "<br>Category:", Category,
    "<br>Subcategory:", Subcategory
  ),
  type = "scattergl",  # Use WebGL for performance
  mode = "markers",
  marker = list(size = 4, opacity = 0.5),
  hoverinfo = "text"  # Display custom text in hover box
) %>%
  layout(
    title = "2D Visualization of sampled Title Embeddings",
    xaxis = list(title = "Dimension 1"),
    yaxis = list(title = "Dimension 2"),
    legend = list(title = list(text = "Category"), traceorder = "normal"),
    width = 1000,
    height = 600
  )

plot
```

<br><br><br><br><br>

While the brown blob in the middle doesn't tell us much, we can see some interesting clusters. Like on the top right the music cluster, on the bottom left the food cluster or top left the fashion cluster. Interesting is also seeing smaller local structures, like the light-blue "peak" on the left, which consists of projects about watches.

These feature embeddings are more relevant ever in our current age of Large Language Models, especially for techniques like Retrieval Augmented Generation (RAG), so getting to play with the basics was very fun & educational.
